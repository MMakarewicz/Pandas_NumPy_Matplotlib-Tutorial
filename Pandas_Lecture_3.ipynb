{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Kopia notatnika 5 - Pandas - Reading CSV and Basic Plotting-checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MMakarewicz/Pandas_NumPy_Matplotlib-Tutorial/blob/main/Pandas_Lecture_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsjaAn8xUJa4"
      },
      "source": [
        "![rmotr](https://user-images.githubusercontent.com/7065401/52071918-bda15380-2562-11e9-828c-7f95297e4a82.png)\n",
        "<hr style=\"margin-bottom: 40px;\">\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/7065401/75165824-badf4680-5701-11ea-9c5b-5475b0a33abf.png\"\n",
        "    style=\"width:300px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
        "\n",
        "# Reading external data & Plotting\n",
        "\n",
        "[Source](https://blockchain.info/charts/market-price)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fped7--pUJa-"
      },
      "source": [
        "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
        "\n",
        "## Hands on! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "es7G3IFaUJbC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt8yHHeTUJbU"
      },
      "source": [
        "Pandas can easily read data stored in different file formats like CSV, JSON, XML or even Excel. Parsing always involves specifying the correct structure, encoding and other details. The `read_csv` method reads CSV files and accepts many parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "j9laXPZjUJbV"
      },
      "source": [
        "pd.read_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVzavH9eUJbj"
      },
      "source": [
        "df = pd.read_csv('data/btc-market-price.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYW2YmW1UJbq"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEswzaHGUJbw"
      },
      "source": [
        "The CSV file we're reading has only two columns: `timestamp` and `price`. It doesn't have a header, it contains whitespaces and has values separated by commas. pandas automatically assigned the first row of data as headers, which is incorrect. We can overwrite this behavior with the `header` parameter:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMqRlS9SUJbw"
      },
      "source": [
        "df = pd.read_csv('data/btc-market-price.csv', header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxhGUAQ7UJb3"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf1iNhxFUJb9"
      },
      "source": [
        "We can then set the names of each column explicitely by setting the `df.columns` attribute:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVegEmRAUJb9"
      },
      "source": [
        "df.columns = ['Timestamp', 'Price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLbUgEBdUJcD"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlpl5pGhUJcG"
      },
      "source": [
        "The type of the `Price` column was correctly interpreted as `float`, but the `Timestamp` was interpreted as a regular string (`object` in pandas notation):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP9Dph6FUJcI"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8jZc0FFUJcM"
      },
      "source": [
        "We can perform a vectorized operation to parse all the Timestamp values as `Datetime` objects:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRS1CwGGUJcM"
      },
      "source": [
        "pd.to_datetime(df['Timestamp']).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USLB_Tu7UJcR"
      },
      "source": [
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TR44wzHqUJcW"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f6px8E3UJcb"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUXtOhz-UJcf"
      },
      "source": [
        "The timestamp looks a lot like the index of this `DataFrame`: `date > price`. We can change the autoincremental ID generated by pandas and use the `Timestamp DS` column as the Index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gqi1SP6UJcg"
      },
      "source": [
        "df.set_index('Timestamp', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKycJKutUJcl"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptV7nm8UUJcq"
      },
      "source": [
        "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
        "\n",
        "## Putting everything together\n",
        "\n",
        "And now, we've finally arrived to the final, desired version of the `DataFrame` parsed from our CSV file. The steps were:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEp9A3POUJcr"
      },
      "source": [
        "df = pd.read_csv('data/btc-market-price.csv', header=None)\n",
        "df.columns = ['Timestamp', 'Price']\n",
        "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
        "df.set_index('Timestamp', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nzN52zJRUJcu"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWFSlU6jUJcx"
      },
      "source": [
        "**There should be a better way**. And there is üòé. And there usually is, explicitly with all these repetitive tasks with pandas.\n",
        "\n",
        "The `read_csv` function is extremely powerful and you can specify many more parameters at import time. We can achive the same results with only one line by doing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFORw2xUJcy"
      },
      "source": [
        "df = pd.read_csv(\n",
        "    'data/btc-market-price.csv',\n",
        "    header=None,\n",
        "    names=['Timestamp', 'Price'],\n",
        "    index_col=0,\n",
        "    parse_dates=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BhWk5GMeUJc2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3PfYP9YUJc5"
      },
      "source": [
        "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
        "\n",
        "## Plotting basics\n",
        "\n",
        "`pandas` integrates with Matplotlib and creating a plot is as simple as:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UO538JOxUJc6"
      },
      "source": [
        "df.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSteuHVdUJc-"
      },
      "source": [
        "Behind the scenes, it's using `matplotlib.pyplot`'s interface. We can create a similar plot with the `plt.plot()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "h5dK5cj0UJc_"
      },
      "source": [
        "plt.plot(df.index, df['Price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W650ceN4UJdE"
      },
      "source": [
        "`plt.plot()` accepts many parameters, but the first two ones are the most important ones: the values for the `X` and `Y` axes. Another example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE3RPZiDUJdF"
      },
      "source": [
        "x = np.arange(-10, 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "FmT5Am27UJdI"
      },
      "source": [
        "plt.plot(x, x ** 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghlbRDFCUJdM"
      },
      "source": [
        "We're using `matplotlib`'s global API, which is horrible but it's the most popular one. We'll learn later how to use the _OOP_ API which will make our work much easier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "z3F5yQFfUJdN"
      },
      "source": [
        "plt.plot(x, x ** 2)\n",
        "plt.plot(x, -1 * (x ** 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilMH9AYbUJdR"
      },
      "source": [
        "Each `plt` function alters the global state. If you want to set settings of your plot you can use the `plt.figure` function. Others like `plt.title` keep altering the global plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "UKm7kfnVUJdS"
      },
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(x, x ** 2)\n",
        "plt.plot(x, -1 * (x ** 2))\n",
        "\n",
        "plt.title('My Nice Plot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzjBy3rVUJdZ"
      },
      "source": [
        "Some of the arguments in `plt.figure` and `plt.plot` are available in the pandas' `plot` interface:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cYg0AZj6UJda"
      },
      "source": [
        "df.plot(figsize=(16, 9), title='Bitcoin Price 2017-2018')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88P-Fwf1UJdd"
      },
      "source": [
        "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
        "\n",
        "## A more challenging parsing\n",
        "\n",
        "To demonstrate plotting two columns together, we'll try to add Ether prices to our `df` DataFrame. The ETH prices data can be found in the `data/eth-price.csv` file. The problem is that it seems like that CSV file was created by someone who really hated programmers. Take a look at it and see how ugly it looks like. We'll still use `pandas` to parse it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "e3EUdbc0UJdd"
      },
      "source": [
        "eth = pd.read_csv('data/eth-price.csv')\n",
        "\n",
        "eth.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWfLA3-3UJdi"
      },
      "source": [
        "As you can see, it has a `Value` column (which represents the price), a `Date(UTC)` one that has a string representing dates and also a `UnixTimeStamp` date represeting the datetime in unix timestamp format. The header is read automatically, let's try to parse dates with the CSV Reader:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmF72xayUJdj"
      },
      "source": [
        "eth = pd.read_csv('data/eth-price.csv', parse_dates=True)\n",
        "\n",
        "print(eth.dtypes)\n",
        "eth.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ5deYLsUJdm"
      },
      "source": [
        "Seems like the `parse_dates` attribute didn't work. We'll need to add a little bit more customization. Let's divide this problem and focus on the problem of \"date parsing\" first. The simplest option would be to use the `UnixTimeStamp` column. The `pandas` module has a `to_datetime` function that converts Unix timestamps to Datetime objects automatically:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0W6wl4DUJdm"
      },
      "source": [
        "pd.to_datetime(eth['UnixTimeStamp']).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv2ssNjzUJdp"
      },
      "source": [
        "The problem is the precision of unix timestamps. To match both columns we'll need to use the same index and, our `df` containing Bitcoin prices, is \"per day\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "I2ShHYvvUJdq"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqzXd_CSUJdt"
      },
      "source": [
        "We could either, remove the precision of `UnixTimeStamp` or attempt to parse the `Date(UTC)`. Let's do String parsing of `Date(UTC)` for fun:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "oUu0VJj5UJdt"
      },
      "source": [
        "pd.to_datetime(eth['Date(UTC)']).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEk8IAtiUJdw"
      },
      "source": [
        "That seems to work fine! Why isn't it then parsing the `Date(UTC)` column? Simple, the `parse_dates=True` parameter will instruct pandas to parse the index of the `DataFrame`. If you want to parse any other column, you must explicitly pass the column position or name:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "srsBJj1zUJdx"
      },
      "source": [
        "pd.read_csv('data/eth-price.csv', parse_dates=[0]).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlAdci8dUJd0"
      },
      "source": [
        "Putting everything together again:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "xnGdrH8mUJd0"
      },
      "source": [
        "eth = pd.read_csv('data/eth-price.csv', parse_dates=True, index_col=0)\n",
        "print(eth.info())\n",
        "\n",
        "eth.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ-XI2T4UJd3"
      },
      "source": [
        "We can now combine both `DataFrame`s into one. Both have the same index, so aligning both prices will be easy. Let's first create an empty `DataFrame` and with the index from Bitcoin prices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P_ekvG4UJd3"
      },
      "source": [
        "prices = pd.DataFrame(index=df.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBypM9XKUJd6"
      },
      "source": [
        "prices.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-I_7Ij1UJd8"
      },
      "source": [
        "And we can now just set columns from the other `DataFrame`s:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khgFI7HzUJd9"
      },
      "source": [
        "prices['Bitcoin'] = df['Price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaLH0VUZUJd_"
      },
      "source": [
        "prices['Ether'] = eth['Value']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztNxKvtZUJeB"
      },
      "source": [
        "prices.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9FHm87LUJeD"
      },
      "source": [
        "We can now try plotting both values:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XBVl-2hvUJeF"
      },
      "source": [
        "prices.plot(figsize=(12, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E27hDM4UJeG"
      },
      "source": [
        "ü§îseems like there's a tiny gap between Dec 2017 and Jan 2018. Let's zoom in there:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "suCWiPCiUJeH"
      },
      "source": [
        "prices.loc['2017-12-01':'2018-01-01'].plot(figsize=(12, 6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwaGs7znUJeJ"
      },
      "source": [
        "Oh no, missing data üò±. We'll learn how to deal with that later üòâ.\n",
        "\n",
        "Btw, did you note that fancy indexing `'2017-12-01':'2018-01-01'` üòè. That's pandas power üí™. We'll learn how to deal with TimeSeries later too."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTMhTQezUJeK"
      },
      "source": [
        "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n"
      ]
    }
  ]
}